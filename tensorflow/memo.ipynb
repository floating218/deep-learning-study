{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 텐서플로를 사용하는 방법(tf.Tensor)\n",
    "\n",
    "- `tf.constant([[1,2,3],[4,5,6]])`\n",
    "- 계산\n",
    "  - `tf.square(t)` \n",
    "  - `t@tf.transpose(t)` \n",
    "  - `tf.add(t,t), tf.multiply(t,t), tf.square(t), tf.exp(t), tf.sqrt(t)`\n",
    "  - `tf.reduce_sum(t), tf.reduce_mean(t), tf.reduce_max(t), tf.math.log(t)`\n",
    "- 형식변경\n",
    "  - `tf.constant(a), t.numpy(), np.array(t), tf.square(a), np.square(t)`\n",
    "- 타입 변경\n",
    "  - `tf.constant(40., dtype=tf.float64)`\n",
    "- 문자열\n",
    "```\n",
    "tf.constant(b\"hello\")\n",
    "tf.constant(\"hello\")\n",
    "enc=tf.strings.unicode_encode(tf.constant([ord(c) for c in \"hello\"]),\"UTF-8\")\n",
    "dec=tf.strings.unicode_decode(enc, \"UTF-8\")\n",
    "```\n",
    "\n",
    "- 희소 텐서 `tf.SparseTensor()`\n",
    "- to_dense `tf.sparse.to_dense(t)` : 희소 텐서를 실제 텐서 형태로 리턴해줌 (0 채워서)\n",
    "```\n",
    "t = tf.SparseTensor(indices=[[0, 1], [1, 0], [2, 3]],\n",
    "                    values=[1., 2., 3.],\n",
    "                    dense_shape=[3, 4])\n",
    "print(t)\n",
    "print(tf.sparse.to_dense(t))\n",
    "```\n",
    "- 집합 `tf.sets.union(tensor1,tensor2)`, `tf.sets.intersection(tensor1,tensor2)`, `tf.sets.difference(tensor1,tensor2)`\n",
    "  \n",
    "# 인덱싱 하는법\n",
    "- `...`와 `:`는 같은 효과이다.\n",
    "```\n",
    "t=tf.constant([[1,2,3],[4,5,6]])\n",
    "\n",
    "print(t[:,1:])\n",
    "print(t[...,1:])\n",
    "\n",
    "```\n",
    "- 인덱싱할 때 `tf.newaxis` 넣으면 1차원을 늘릴수가 있다. \n",
    "```\n",
    "t=tf.constant([[1,2,3],[4,5,6]])\n",
    "\n",
    "t[:,:].shape, t[:,:,tf.newaxis].shape #(2,3) -> (2,3,1)\n",
    "t[:,1].shape, t[:,1,tf.newaxis].shape #(2) -> (2,1)\n",
    "t[1,:].shape, t[tf.newaxis,1,:].shape #(3) -> (1,3)\n",
    "```\n",
    "\n",
    "# tf.Variable\n",
    "- 변수에 해당하는 Variable은 변숫값을 함부러 바꾸지 못하고, v.assign을 통해 바꿀 수 있다. \n",
    "```\n",
    "v = tf.Variable([[1., 2., 3.], [4., 5., 6.]])\n",
    "v.assign(2*v)\n",
    "```\n",
    "- 그 외 `v.assign_add()`, `v.assign_sub()`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "t=tf.constant([[1,2,3],[4,5,6]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       " array([[2, 3],\n",
       "        [5, 6]])>,\n",
       " <tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       " array([[2, 3],\n",
       "        [5, 6]])>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[:,1:],t[...,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([3]), TensorShape([1, 3]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t=tf.constant([[1,2,3],[4,5,6]])\n",
    "new=t[:,:,tf.newaxis] #\n",
    "t[:,:].shape, t[:,:,tf.newaxis].shape #(2,3) -> (2,3,1)\n",
    "t[:,1].shape, t[:,1,tf.newaxis].shape #(2) -> (2,1)\n",
    "t[1,:].shape, t[tf.newaxis,1,:].shape #(3) -> (1,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 공통  \n",
    "- `__init__(self, **kwargs)`\n",
    "- `get_config(self)`   \n",
    "# 사용자 정의 손실 함수  \n",
    "- `keras.losses.Loss`를 상속받으며, `call(self,y_true,y_pred)`에서 새로운 loss 결과를 리턴한다.  \n",
    "- `model.compile(loss=Loss클래스(), optimizer=..., metrics=[...])`    \n",
    "# 사용자 정의 활성화함수(activation) / 초기화(initializer) / 규제(regularizer) / 제한(constraint)   \n",
    "- `model.layers.Dense(안에, activation='', kernel_regularizer='', kernel_initializer='', kernel_constraint='')\n",
    "- initializer함수: shape를 받아서 초기화하는 함수\n",
    "- regularizer함수: weights을 받아서, 원래의 Loss에 더해지는 값\n",
    "- constraint함수: weights를 받아서, weights와 같은 차원을 값으로 변형해서 리턴해주는 함수  \n",
    "# 사용자 정의 metric 함수  \n",
    "- `keras.metrics.Metric`을 상속받으며, `update_state(self,y_true,y_pred)` -> `result(self)`순서로 호출\n",
    "- result에 새로운 metric 결과를 리턴한다\n",
    "- `model.complie(loss=..., optimizer=..., weighted_metrics=[Metric클래스()])`  \n",
    "# 사용자 지정 레이어\n",
    "- `keras.layers.Layer`를 상속 받음\n",
    "- `build()`: 가중치마다 add_weights() 메서드를 호출하여 층의 변수를 만든다. 층이 처음 사용될 때 호출된다. 필수 메서드는 아니다.\n",
    "- `call()`: 층에 필요한 연산을 수행한다. 활성화 함수까지 들어간다. 이 값이 층의 출력에 해당한다. \n",
    "- `call()`안에 `training=None` 옵션을 넣으면 학습과 검증을 다르게 할 수 있다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5812e37fbc42ae0019c075dcd625ea6adf837b197758e07cfdfe5b415c77a600"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
