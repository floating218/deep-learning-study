{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "http://melonicedlatte.com/datascience/2019/10/19/140600.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파이썬 ≥3.5 필수\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# 사이킷런 ≥0.20 필수\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "try:\n",
    "    # %tensorflow_version은 코랩 명령입니다.\n",
    "    %tensorflow_version 2.x\n",
    "    !pip install -q -U tfx\n",
    "    print(\"패키지 호환 에러는 무시해도 괜찮습니다.\")\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# 텐서플로 ≥2.0 필수\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "assert tf.__version__ >= \"2.0\"\n",
    "\n",
    "# 공통 모듈 임포트\u001f\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# 노트북 실행 결과를 동일하게 유지하기 위해\n",
    "np.random.seed(40)\n",
    "\n",
    "# 깔끔한 그래프 출력을 위해\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"datasets/titanic/train.csv\", sep=',')\n",
    "test = pd.read_csv(\"datasets/titanic/test.csv\", sep=',')\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= train.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "\n",
    "def process_titanic(train):\n",
    "    train=train.copy().dropna()\n",
    "    train['Ageten']=[int(a/20) if a!=np.NaN else None  for a in train['Age']]\n",
    "    train['Embarked']=[0 if e=='S' else 1 if e=='C' else 2  for e in train['Embarked']]\n",
    "    train['Fare']=[10 if f>100 else int(f/10)  for f in train['Fare']]\n",
    "    \n",
    "    train_x=train.copy()\n",
    "    train_x['Title'] = train_x.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "    train_x['Title'] = train_x['Title'].replace(['Lady', 'Countess','Capt', 'Col', 'Don',\\\n",
    "                                                'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'],\\\n",
    "                                                'Rare')\n",
    "    train_x['Title'] = train_x['Title'].replace('Mlle', 'Miss')\n",
    "    train_x['Title'] = train_x['Title'].replace('Ms', 'Miss')\n",
    "    train_x['Title'] = train_x['Title'].replace('Mme', 'Mrs')\n",
    "    _, train_x['Title'] = np.unique(train_x['Title'], return_inverse=True)\n",
    "    _, train_x['Sex'] = np.unique(train_x['Sex'], return_inverse=True)\n",
    "    \n",
    "    train_y = np.ravel(train_x.Survived) # Make 1D\n",
    "    train_x.drop(['Survived'], inplace=True, axis=1)\n",
    "    return train_x, train_y\n",
    "\n",
    "def train_general_model(train_x,train_y):\n",
    "    \n",
    "    keras.backend.clear_session()  \n",
    "    np.random.seed(40)\n",
    "    tf.random.set_seed(40)\n",
    "    \n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(16, activation='relu', input_shape=(train_x.shape[1],)))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                optimizer='adam',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "    model.fit(train_x, train_y, epochs=50, batch_size=4, verbose=1)\n",
    "\n",
    "def train_embedding_model(train_x,train_y):\n",
    "    \n",
    "    keras.backend.clear_session()  \n",
    "    np.random.seed(40)\n",
    "    tf.random.set_seed(40)\n",
    "    \n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Embedding(50, 10, input_length=train_x.shape[1]))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(16, activation='relu', input_shape=(10,)))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                optimizer='adam',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "    model.fit(train_x, train_y, epochs=50, batch_size=4, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Pclass  Sex  Ageten  Title\n",
      "1        1    0       1      3\n",
      "3        1    0       1      3\n",
      "6        1    1       2      2\n",
      "10       3    0       0      1\n",
      "11       1    0       2      1\n",
      "Epoch 1/50\n",
      "46/46 [==============================] - 0s 975us/step - loss: 0.7032 - accuracy: 0.5464\n",
      "Epoch 2/50\n",
      "46/46 [==============================] - 0s 665us/step - loss: 0.6783 - accuracy: 0.6503\n",
      "Epoch 3/50\n",
      "46/46 [==============================] - 0s 616us/step - loss: 0.6594 - accuracy: 0.6557\n",
      "Epoch 4/50\n",
      "46/46 [==============================] - 0s 598us/step - loss: 0.6406 - accuracy: 0.6721\n",
      "Epoch 5/50\n",
      "46/46 [==============================] - 0s 643us/step - loss: 0.6252 - accuracy: 0.6721\n",
      "Epoch 6/50\n",
      "46/46 [==============================] - 0s 598us/step - loss: 0.6098 - accuracy: 0.6721\n",
      "Epoch 7/50\n",
      "46/46 [==============================] - 0s 610us/step - loss: 0.5968 - accuracy: 0.6721\n",
      "Epoch 8/50\n",
      "46/46 [==============================] - 0s 621us/step - loss: 0.5860 - accuracy: 0.6995\n",
      "Epoch 9/50\n",
      "46/46 [==============================] - 0s 820us/step - loss: 0.5752 - accuracy: 0.7049\n",
      "Epoch 10/50\n",
      "46/46 [==============================] - 0s 632us/step - loss: 0.5643 - accuracy: 0.7268\n",
      "Epoch 11/50\n",
      "46/46 [==============================] - 0s 621us/step - loss: 0.5560 - accuracy: 0.7213\n",
      "Epoch 12/50\n",
      "46/46 [==============================] - 0s 665us/step - loss: 0.5442 - accuracy: 0.7650\n",
      "Epoch 13/50\n",
      "46/46 [==============================] - 0s 643us/step - loss: 0.5367 - accuracy: 0.7650\n",
      "Epoch 14/50\n",
      "46/46 [==============================] - 0s 621us/step - loss: 0.5284 - accuracy: 0.7650\n",
      "Epoch 15/50\n",
      "46/46 [==============================] - 0s 621us/step - loss: 0.5188 - accuracy: 0.7650\n",
      "Epoch 16/50\n",
      "46/46 [==============================] - 0s 598us/step - loss: 0.5115 - accuracy: 0.7541\n",
      "Epoch 17/50\n",
      "46/46 [==============================] - 0s 975us/step - loss: 0.5021 - accuracy: 0.7650\n",
      "Epoch 18/50\n",
      "46/46 [==============================] - 0s 621us/step - loss: 0.4935 - accuracy: 0.7650\n",
      "Epoch 19/50\n",
      "46/46 [==============================] - 0s 643us/step - loss: 0.4898 - accuracy: 0.7486\n",
      "Epoch 20/50\n",
      "46/46 [==============================] - 0s 687us/step - loss: 0.4823 - accuracy: 0.7268\n",
      "Epoch 21/50\n",
      "46/46 [==============================] - 0s 665us/step - loss: 0.4755 - accuracy: 0.7596\n",
      "Epoch 22/50\n",
      "46/46 [==============================] - 0s 576us/step - loss: 0.4724 - accuracy: 0.7268\n",
      "Epoch 23/50\n",
      "46/46 [==============================] - 0s 643us/step - loss: 0.4686 - accuracy: 0.7596\n",
      "Epoch 24/50\n",
      "46/46 [==============================] - 0s 864us/step - loss: 0.4636 - accuracy: 0.7596\n",
      "Epoch 25/50\n",
      "46/46 [==============================] - 0s 598us/step - loss: 0.4581 - accuracy: 0.7541\n",
      "Epoch 26/50\n",
      "46/46 [==============================] - 0s 621us/step - loss: 0.4542 - accuracy: 0.7596\n",
      "Epoch 27/50\n",
      "46/46 [==============================] - 0s 607us/step - loss: 0.4543 - accuracy: 0.7541\n",
      "Epoch 28/50\n",
      "46/46 [==============================] - 0s 621us/step - loss: 0.4486 - accuracy: 0.7596\n",
      "Epoch 29/50\n",
      "46/46 [==============================] - 0s 621us/step - loss: 0.4465 - accuracy: 0.7650\n",
      "Epoch 30/50\n",
      "46/46 [==============================] - 0s 709us/step - loss: 0.4445 - accuracy: 0.7705\n",
      "Epoch 31/50\n",
      "46/46 [==============================] - 0s 731us/step - loss: 0.4415 - accuracy: 0.7650\n",
      "Epoch 32/50\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.4402 - accuracy: 0.7760\n",
      "Epoch 33/50\n",
      "46/46 [==============================] - 0s 621us/step - loss: 0.4379 - accuracy: 0.7760\n",
      "Epoch 34/50\n",
      "46/46 [==============================] - 0s 598us/step - loss: 0.4343 - accuracy: 0.7814\n",
      "Epoch 35/50\n",
      "46/46 [==============================] - 0s 621us/step - loss: 0.4332 - accuracy: 0.7814\n",
      "Epoch 36/50\n",
      "46/46 [==============================] - 0s 618us/step - loss: 0.4303 - accuracy: 0.7869\n",
      "Epoch 37/50\n",
      "46/46 [==============================] - 0s 576us/step - loss: 0.4316 - accuracy: 0.7869\n",
      "Epoch 38/50\n",
      "46/46 [==============================] - 0s 598us/step - loss: 0.4292 - accuracy: 0.7869\n",
      "Epoch 39/50\n",
      "46/46 [==============================] - 0s 598us/step - loss: 0.4284 - accuracy: 0.7869\n",
      "Epoch 40/50\n",
      "46/46 [==============================] - 0s 820us/step - loss: 0.4261 - accuracy: 0.7869\n",
      "Epoch 41/50\n",
      "46/46 [==============================] - 0s 615us/step - loss: 0.4268 - accuracy: 0.7923\n",
      "Epoch 42/50\n",
      "46/46 [==============================] - 0s 598us/step - loss: 0.4260 - accuracy: 0.7869\n",
      "Epoch 43/50\n",
      "46/46 [==============================] - 0s 598us/step - loss: 0.4241 - accuracy: 0.7869\n",
      "Epoch 44/50\n",
      "46/46 [==============================] - 0s 598us/step - loss: 0.4234 - accuracy: 0.7869\n",
      "Epoch 45/50\n",
      "46/46 [==============================] - 0s 576us/step - loss: 0.4210 - accuracy: 0.7923\n",
      "Epoch 46/50\n",
      "46/46 [==============================] - 0s 598us/step - loss: 0.4207 - accuracy: 0.7923\n",
      "Epoch 47/50\n",
      "46/46 [==============================] - 0s 576us/step - loss: 0.4250 - accuracy: 0.7869\n",
      "Epoch 48/50\n",
      "46/46 [==============================] - 0s 743us/step - loss: 0.4247 - accuracy: 0.7923\n",
      "Epoch 49/50\n",
      "46/46 [==============================] - 0s 576us/step - loss: 0.4212 - accuracy: 0.7869\n",
      "Epoch 50/50\n",
      "46/46 [==============================] - 0s 598us/step - loss: 0.4188 - accuracy: 0.7869\n"
     ]
    }
   ],
   "source": [
    "#1.embedding을 사용하지 않음\n",
    "train_x,train_y=process_titanic(train.copy())\n",
    "cols=['Pclass','Sex','Ageten','Title']\n",
    "train_x=train_x[cols]\n",
    "print(train_x.head())\n",
    "\n",
    "train_general_model(train_x,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Pclass  Sex  Ageten  Title\n",
      "1        1    0       1      3\n",
      "3        1    0       1      3\n",
      "6        1    1       2      2\n",
      "10       3    0       0      1\n",
      "11       1    0       2      1\n",
      "Epoch 1/50\n",
      "46/46 [==============================] - 0s 630us/step - loss: 0.6777 - accuracy: 0.6503\n",
      "Epoch 2/50\n",
      "46/46 [==============================] - 0s 621us/step - loss: 0.6233 - accuracy: 0.6721\n",
      "Epoch 3/50\n",
      "46/46 [==============================] - 0s 665us/step - loss: 0.5328 - accuracy: 0.6721\n",
      "Epoch 4/50\n",
      "46/46 [==============================] - 0s 663us/step - loss: 0.4822 - accuracy: 0.7104\n",
      "Epoch 5/50\n",
      "46/46 [==============================] - 0s 665us/step - loss: 0.4709 - accuracy: 0.7705\n",
      "Epoch 6/50\n",
      "46/46 [==============================] - 0s 997us/step - loss: 0.4664 - accuracy: 0.7869\n",
      "Epoch 7/50\n",
      "46/46 [==============================] - 0s 665us/step - loss: 0.4615 - accuracy: 0.7869\n",
      "Epoch 8/50\n",
      "46/46 [==============================] - 0s 665us/step - loss: 0.4569 - accuracy: 0.7869\n",
      "Epoch 9/50\n",
      "46/46 [==============================] - 0s 687us/step - loss: 0.4518 - accuracy: 0.7923\n",
      "Epoch 10/50\n",
      "46/46 [==============================] - 0s 687us/step - loss: 0.4472 - accuracy: 0.7705\n",
      "Epoch 11/50\n",
      "46/46 [==============================] - 0s 709us/step - loss: 0.4449 - accuracy: 0.7760\n",
      "Epoch 12/50\n",
      "46/46 [==============================] - 0s 709us/step - loss: 0.4384 - accuracy: 0.7923\n",
      "Epoch 13/50\n",
      "46/46 [==============================] - 0s 931us/step - loss: 0.4369 - accuracy: 0.7760\n",
      "Epoch 14/50\n",
      "46/46 [==============================] - 0s 731us/step - loss: 0.4338 - accuracy: 0.7705\n",
      "Epoch 15/50\n",
      "46/46 [==============================] - 0s 709us/step - loss: 0.4285 - accuracy: 0.7869\n",
      "Epoch 16/50\n",
      "46/46 [==============================] - 0s 687us/step - loss: 0.4267 - accuracy: 0.7869\n",
      "Epoch 17/50\n",
      "46/46 [==============================] - 0s 709us/step - loss: 0.4219 - accuracy: 0.8087\n",
      "Epoch 18/50\n",
      "46/46 [==============================] - 0s 754us/step - loss: 0.4201 - accuracy: 0.7978\n",
      "Epoch 19/50\n",
      "46/46 [==============================] - 0s 842us/step - loss: 0.4185 - accuracy: 0.7869\n",
      "Epoch 20/50\n",
      "46/46 [==============================] - 0s 864us/step - loss: 0.4170 - accuracy: 0.7760\n",
      "Epoch 21/50\n",
      "46/46 [==============================] - 0s 731us/step - loss: 0.4136 - accuracy: 0.7978\n",
      "Epoch 22/50\n",
      "46/46 [==============================] - 0s 709us/step - loss: 0.4138 - accuracy: 0.7705\n",
      "Epoch 23/50\n",
      "46/46 [==============================] - 0s 687us/step - loss: 0.4097 - accuracy: 0.7814\n",
      "Epoch 24/50\n",
      "46/46 [==============================] - 0s 687us/step - loss: 0.4120 - accuracy: 0.7705\n",
      "Epoch 25/50\n",
      "46/46 [==============================] - 0s 687us/step - loss: 0.4097 - accuracy: 0.7978\n",
      "Epoch 26/50\n",
      "46/46 [==============================] - 0s 798us/step - loss: 0.4082 - accuracy: 0.7869\n",
      "Epoch 27/50\n",
      "46/46 [==============================] - 0s 682us/step - loss: 0.4088 - accuracy: 0.7760\n",
      "Epoch 28/50\n",
      "46/46 [==============================] - 0s 665us/step - loss: 0.4044 - accuracy: 0.8033\n",
      "Epoch 29/50\n",
      "46/46 [==============================] - 0s 684us/step - loss: 0.4047 - accuracy: 0.7596\n",
      "Epoch 30/50\n",
      "46/46 [==============================] - 0s 731us/step - loss: 0.4054 - accuracy: 0.7486\n",
      "Epoch 31/50\n",
      "46/46 [==============================] - 0s 687us/step - loss: 0.4049 - accuracy: 0.7978\n",
      "Epoch 32/50\n",
      "46/46 [==============================] - 0s 687us/step - loss: 0.4011 - accuracy: 0.7814\n",
      "Epoch 33/50\n",
      "46/46 [==============================] - 0s 687us/step - loss: 0.4024 - accuracy: 0.7814\n",
      "Epoch 34/50\n",
      "46/46 [==============================] - 0s 953us/step - loss: 0.4015 - accuracy: 0.7650\n",
      "Epoch 35/50\n",
      "46/46 [==============================] - 0s 643us/step - loss: 0.3998 - accuracy: 0.7923\n",
      "Epoch 36/50\n",
      "46/46 [==============================] - 0s 665us/step - loss: 0.3983 - accuracy: 0.7923\n",
      "Epoch 37/50\n",
      "46/46 [==============================] - 0s 687us/step - loss: 0.4017 - accuracy: 0.7596\n",
      "Epoch 38/50\n",
      "46/46 [==============================] - 0s 709us/step - loss: 0.3991 - accuracy: 0.7923\n",
      "Epoch 39/50\n",
      "46/46 [==============================] - 0s 798us/step - loss: 0.3975 - accuracy: 0.7978\n",
      "Epoch 40/50\n",
      "46/46 [==============================] - 0s 687us/step - loss: 0.3992 - accuracy: 0.7978\n",
      "Epoch 41/50\n",
      "46/46 [==============================] - 0s 798us/step - loss: 0.4008 - accuracy: 0.7923\n",
      "Epoch 42/50\n",
      "46/46 [==============================] - 0s 665us/step - loss: 0.4007 - accuracy: 0.7978\n",
      "Epoch 43/50\n",
      "46/46 [==============================] - 0s 687us/step - loss: 0.3960 - accuracy: 0.7923\n",
      "Epoch 44/50\n",
      "46/46 [==============================] - 0s 687us/step - loss: 0.3961 - accuracy: 0.7869\n",
      "Epoch 45/50\n",
      "46/46 [==============================] - 0s 687us/step - loss: 0.3946 - accuracy: 0.7978\n",
      "Epoch 46/50\n",
      "46/46 [==============================] - 0s 643us/step - loss: 0.3957 - accuracy: 0.7978\n",
      "Epoch 47/50\n",
      "46/46 [==============================] - 0s 687us/step - loss: 0.3998 - accuracy: 0.8033\n",
      "Epoch 48/50\n",
      "46/46 [==============================] - 0s 997us/step - loss: 0.4000 - accuracy: 0.8033\n",
      "Epoch 49/50\n",
      "46/46 [==============================] - 0s 665us/step - loss: 0.3955 - accuracy: 0.7760\n",
      "Epoch 50/50\n",
      "46/46 [==============================] - 0s 665us/step - loss: 0.3935 - accuracy: 0.8033\n"
     ]
    }
   ],
   "source": [
    "#2.embedding을 사용함\n",
    "train_x,train_y=process_titanic(train.copy())\n",
    "cols=['Pclass','Sex','Ageten','Title']\n",
    "train_x=train_x[cols]\n",
    "print(train_x.head())\n",
    "\n",
    "train_embedding_model(train_x,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Pclass  Sex  Title\n",
      "1        1    0      3\n",
      "3        1    0      3\n",
      "6        1    1      2\n",
      "10       3    0      1\n",
      "11       1    0      1\n",
      "Epoch 1/50\n",
      "46/46 [==============================] - 0s 842us/step - loss: 0.6767 - accuracy: 0.6667\n",
      "Epoch 2/50\n",
      "46/46 [==============================] - 0s 665us/step - loss: 0.6217 - accuracy: 0.6721\n",
      "Epoch 3/50\n",
      "46/46 [==============================] - 0s 687us/step - loss: 0.5306 - accuracy: 0.6612\n",
      "Epoch 4/50\n",
      "46/46 [==============================] - 0s 687us/step - loss: 0.4792 - accuracy: 0.7486\n",
      "Epoch 5/50\n",
      "46/46 [==============================] - 0s 643us/step - loss: 0.4660 - accuracy: 0.7814\n",
      "Epoch 6/50\n",
      "46/46 [==============================] - 0s 665us/step - loss: 0.4595 - accuracy: 0.7869\n",
      "Epoch 7/50\n",
      "46/46 [==============================] - 0s 665us/step - loss: 0.4549 - accuracy: 0.7869\n",
      "Epoch 8/50\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.4516 - accuracy: 0.7869\n",
      "Epoch 9/50\n",
      "46/46 [==============================] - 0s 731us/step - loss: 0.4478 - accuracy: 0.7869\n",
      "Epoch 10/50\n",
      "46/46 [==============================] - 0s 687us/step - loss: 0.4457 - accuracy: 0.7869\n",
      "Epoch 11/50\n",
      "46/46 [==============================] - 0s 687us/step - loss: 0.4432 - accuracy: 0.7869\n",
      "Epoch 12/50\n",
      "46/46 [==============================] - 0s 665us/step - loss: 0.4405 - accuracy: 0.7869\n",
      "Epoch 13/50\n",
      "46/46 [==============================] - 0s 665us/step - loss: 0.4410 - accuracy: 0.7869\n",
      "Epoch 14/50\n",
      "46/46 [==============================] - 0s 687us/step - loss: 0.4407 - accuracy: 0.7869\n",
      "Epoch 15/50\n",
      "46/46 [==============================] - 0s 864us/step - loss: 0.4369 - accuracy: 0.7869\n",
      "Epoch 16/50\n",
      "46/46 [==============================] - 0s 665us/step - loss: 0.4360 - accuracy: 0.7869\n",
      "Epoch 17/50\n",
      "46/46 [==============================] - 0s 665us/step - loss: 0.4350 - accuracy: 0.7869\n",
      "Epoch 18/50\n",
      "46/46 [==============================] - 0s 687us/step - loss: 0.4332 - accuracy: 0.7869\n",
      "Epoch 19/50\n",
      "46/46 [==============================] - 0s 754us/step - loss: 0.4333 - accuracy: 0.7869\n",
      "Epoch 20/50\n",
      "46/46 [==============================] - 0s 776us/step - loss: 0.4311 - accuracy: 0.7869\n",
      "Epoch 21/50\n",
      "46/46 [==============================] - 0s 665us/step - loss: 0.4309 - accuracy: 0.7869\n",
      "Epoch 22/50\n",
      "46/46 [==============================] - 0s 975us/step - loss: 0.4299 - accuracy: 0.7869\n",
      "Epoch 23/50\n",
      "46/46 [==============================] - 0s 709us/step - loss: 0.4284 - accuracy: 0.7869\n",
      "Epoch 24/50\n",
      "46/46 [==============================] - 0s 663us/step - loss: 0.4279 - accuracy: 0.7869\n",
      "Epoch 25/50\n",
      "46/46 [==============================] - 0s 643us/step - loss: 0.4287 - accuracy: 0.7869\n",
      "Epoch 26/50\n",
      "46/46 [==============================] - 0s 687us/step - loss: 0.4277 - accuracy: 0.7869\n",
      "Epoch 27/50\n",
      "46/46 [==============================] - 0s 680us/step - loss: 0.4273 - accuracy: 0.7869\n",
      "Epoch 28/50\n",
      "46/46 [==============================] - 0s 731us/step - loss: 0.4268 - accuracy: 0.7869\n",
      "Epoch 29/50\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.4278 - accuracy: 0.7869\n",
      "Epoch 30/50\n",
      "46/46 [==============================] - 0s 709us/step - loss: 0.4257 - accuracy: 0.7869\n",
      "Epoch 31/50\n",
      "46/46 [==============================] - 0s 687us/step - loss: 0.4264 - accuracy: 0.7869\n",
      "Epoch 32/50\n",
      "46/46 [==============================] - 0s 655us/step - loss: 0.4254 - accuracy: 0.7869\n",
      "Epoch 33/50\n",
      "46/46 [==============================] - 0s 665us/step - loss: 0.4258 - accuracy: 0.7869\n",
      "Epoch 34/50\n",
      "46/46 [==============================] - 0s 643us/step - loss: 0.4249 - accuracy: 0.7869\n",
      "Epoch 35/50\n",
      "46/46 [==============================] - 0s 643us/step - loss: 0.4247 - accuracy: 0.7869\n",
      "Epoch 36/50\n",
      "46/46 [==============================] - 0s 754us/step - loss: 0.4241 - accuracy: 0.7869\n",
      "Epoch 37/50\n",
      "46/46 [==============================] - 0s 798us/step - loss: 0.4258 - accuracy: 0.7869\n",
      "Epoch 38/50\n",
      "46/46 [==============================] - 0s 632us/step - loss: 0.4248 - accuracy: 0.7869\n",
      "Epoch 39/50\n",
      "46/46 [==============================] - 0s 665us/step - loss: 0.4242 - accuracy: 0.7869\n",
      "Epoch 40/50\n",
      "46/46 [==============================] - 0s 621us/step - loss: 0.4237 - accuracy: 0.7869\n",
      "Epoch 41/50\n",
      "46/46 [==============================] - 0s 665us/step - loss: 0.4251 - accuracy: 0.7869\n",
      "Epoch 42/50\n",
      "46/46 [==============================] - 0s 687us/step - loss: 0.4259 - accuracy: 0.7814\n",
      "Epoch 43/50\n",
      "46/46 [==============================] - 0s 643us/step - loss: 0.4236 - accuracy: 0.7869\n",
      "Epoch 44/50\n",
      "46/46 [==============================] - 0s 820us/step - loss: 0.4241 - accuracy: 0.7869\n",
      "Epoch 45/50\n",
      "46/46 [==============================] - 0s 687us/step - loss: 0.4234 - accuracy: 0.7869\n",
      "Epoch 46/50\n",
      "46/46 [==============================] - 0s 643us/step - loss: 0.4238 - accuracy: 0.7869\n",
      "Epoch 47/50\n",
      "46/46 [==============================] - 0s 665us/step - loss: 0.4250 - accuracy: 0.7869\n",
      "Epoch 48/50\n",
      "46/46 [==============================] - 0s 643us/step - loss: 0.4262 - accuracy: 0.7869\n",
      "Epoch 49/50\n",
      "46/46 [==============================] - 0s 643us/step - loss: 0.4236 - accuracy: 0.7869\n",
      "Epoch 50/50\n",
      "46/46 [==============================] - 0s 709us/step - loss: 0.4233 - accuracy: 0.7869\n"
     ]
    }
   ],
   "source": [
    "#3.Ageten제외\n",
    "train_x,train_y=process_titanic(train.copy())\n",
    "cols=['Pclass','Sex','Title']\n",
    "train_x=train_x[cols]\n",
    "print(train_x.head())\n",
    "\n",
    "train_embedding_model(train_x,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Pclass  Sex  Ageten  SibSp  Parch  Embarked  Fare\n",
      "1        1    0       1      1      0         1     7\n",
      "3        1    0       1      1      0         0     5\n",
      "6        1    1       2      0      0         0     5\n",
      "10       3    0       0      1      1         0     1\n",
      "11       1    0       2      0      0         0     2\n",
      "Epoch 1/50\n",
      "46/46 [==============================] - 0s 643us/step - loss: 0.6811 - accuracy: 0.6503\n",
      "Epoch 2/50\n",
      "46/46 [==============================] - 0s 621us/step - loss: 0.6446 - accuracy: 0.6721\n",
      "Epoch 3/50\n",
      "46/46 [==============================] - 0s 685us/step - loss: 0.5792 - accuracy: 0.6721\n",
      "Epoch 4/50\n",
      "46/46 [==============================] - 0s 754us/step - loss: 0.5181 - accuracy: 0.6940\n",
      "Epoch 5/50\n",
      "46/46 [==============================] - 0s 842us/step - loss: 0.4816 - accuracy: 0.7322\n",
      "Epoch 6/50\n",
      "46/46 [==============================] - 0s 665us/step - loss: 0.4659 - accuracy: 0.7596\n",
      "Epoch 7/50\n",
      "46/46 [==============================] - 0s 665us/step - loss: 0.4558 - accuracy: 0.7760\n",
      "Epoch 8/50\n",
      "46/46 [==============================] - 0s 687us/step - loss: 0.4513 - accuracy: 0.7814\n",
      "Epoch 9/50\n",
      "46/46 [==============================] - 0s 709us/step - loss: 0.4428 - accuracy: 0.7978\n",
      "Epoch 10/50\n",
      "46/46 [==============================] - 0s 687us/step - loss: 0.4380 - accuracy: 0.8087\n",
      "Epoch 11/50\n",
      "46/46 [==============================] - 0s 709us/step - loss: 0.4336 - accuracy: 0.7978\n",
      "Epoch 12/50\n",
      "46/46 [==============================] - 0s 889us/step - loss: 0.4244 - accuracy: 0.8142\n",
      "Epoch 13/50\n",
      "46/46 [==============================] - 0s 687us/step - loss: 0.4200 - accuracy: 0.8197\n",
      "Epoch 14/50\n",
      "46/46 [==============================] - 0s 665us/step - loss: 0.4153 - accuracy: 0.8087\n",
      "Epoch 15/50\n",
      "46/46 [==============================] - 0s 680us/step - loss: 0.4091 - accuracy: 0.8087\n",
      "Epoch 16/50\n",
      "46/46 [==============================] - 0s 665us/step - loss: 0.4055 - accuracy: 0.8142\n",
      "Epoch 17/50\n",
      "46/46 [==============================] - 0s 731us/step - loss: 0.3991 - accuracy: 0.8306\n",
      "Epoch 18/50\n",
      "46/46 [==============================] - 0s 698us/step - loss: 0.3929 - accuracy: 0.8197\n",
      "Epoch 19/50\n",
      "46/46 [==============================] - 0s 953us/step - loss: 0.3881 - accuracy: 0.8361\n",
      "Epoch 20/50\n",
      "46/46 [==============================] - 0s 665us/step - loss: 0.3825 - accuracy: 0.8306\n",
      "Epoch 21/50\n",
      "46/46 [==============================] - 0s 687us/step - loss: 0.3777 - accuracy: 0.8197\n",
      "Epoch 22/50\n",
      "46/46 [==============================] - 0s 687us/step - loss: 0.3753 - accuracy: 0.8306\n",
      "Epoch 23/50\n",
      "46/46 [==============================] - 0s 687us/step - loss: 0.3685 - accuracy: 0.8251\n",
      "Epoch 24/50\n",
      "46/46 [==============================] - 0s 754us/step - loss: 0.3690 - accuracy: 0.8361\n",
      "Epoch 25/50\n",
      "46/46 [==============================] - 0s 665us/step - loss: 0.3612 - accuracy: 0.8415\n",
      "Epoch 26/50\n",
      "46/46 [==============================] - 0s 975us/step - loss: 0.3574 - accuracy: 0.8306\n",
      "Epoch 27/50\n",
      "46/46 [==============================] - 0s 665us/step - loss: 0.3568 - accuracy: 0.8415\n",
      "Epoch 28/50\n",
      "46/46 [==============================] - 0s 665us/step - loss: 0.3460 - accuracy: 0.8634\n",
      "Epoch 29/50\n",
      "46/46 [==============================] - 0s 945us/step - loss: 0.3443 - accuracy: 0.8525\n",
      "Epoch 30/50\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3401 - accuracy: 0.8743\n",
      "Epoch 31/50\n",
      "46/46 [==============================] - 0s 864us/step - loss: 0.3359 - accuracy: 0.8689\n",
      "Epoch 32/50\n",
      "46/46 [==============================] - 0s 931us/step - loss: 0.3357 - accuracy: 0.8743\n",
      "Epoch 33/50\n",
      "46/46 [==============================] - 0s 709us/step - loss: 0.3274 - accuracy: 0.8743\n",
      "Epoch 34/50\n",
      "46/46 [==============================] - 0s 687us/step - loss: 0.3222 - accuracy: 0.8743\n",
      "Epoch 35/50\n",
      "46/46 [==============================] - 0s 709us/step - loss: 0.3214 - accuracy: 0.8743\n",
      "Epoch 36/50\n",
      "46/46 [==============================] - 0s 731us/step - loss: 0.3126 - accuracy: 0.8798\n",
      "Epoch 37/50\n",
      "46/46 [==============================] - 0s 731us/step - loss: 0.3120 - accuracy: 0.8798\n",
      "Epoch 38/50\n",
      "46/46 [==============================] - 0s 909us/step - loss: 0.3058 - accuracy: 0.8852\n",
      "Epoch 39/50\n",
      "46/46 [==============================] - 0s 820us/step - loss: 0.3025 - accuracy: 0.8798\n",
      "Epoch 40/50\n",
      "46/46 [==============================] - 0s 709us/step - loss: 0.3011 - accuracy: 0.8907\n",
      "Epoch 41/50\n",
      "46/46 [==============================] - 0s 709us/step - loss: 0.2955 - accuracy: 0.8962\n",
      "Epoch 42/50\n",
      "46/46 [==============================] - 0s 842us/step - loss: 0.2949 - accuracy: 0.8907\n",
      "Epoch 43/50\n",
      "46/46 [==============================] - 0s 754us/step - loss: 0.2829 - accuracy: 0.8852\n",
      "Epoch 44/50\n",
      "46/46 [==============================] - 0s 754us/step - loss: 0.2853 - accuracy: 0.8907\n",
      "Epoch 45/50\n",
      "46/46 [==============================] - 0s 953us/step - loss: 0.2820 - accuracy: 0.8962\n",
      "Epoch 46/50\n",
      "46/46 [==============================] - 0s 709us/step - loss: 0.2786 - accuracy: 0.8907\n",
      "Epoch 47/50\n",
      "46/46 [==============================] - 0s 723us/step - loss: 0.2761 - accuracy: 0.8907\n",
      "Epoch 48/50\n",
      "46/46 [==============================] - 0s 731us/step - loss: 0.2792 - accuracy: 0.8798\n",
      "Epoch 49/50\n",
      "46/46 [==============================] - 0s 721us/step - loss: 0.2667 - accuracy: 0.8962\n",
      "Epoch 50/50\n",
      "46/46 [==============================] - 0s 687us/step - loss: 0.2640 - accuracy: 0.8907\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#2.embedding을 사용함\n",
    "train_x,train_y=process_titanic(train.copy())\n",
    "cols=['Pclass','Sex','Ageten','SibSp','Parch','Embarked','Fare']\n",
    "train_x=train_x[cols]\n",
    "print(train_x.head())\n",
    "\n",
    "train_embedding_model(train_x,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab=train['Sex'].drop_duplicates()\n",
    "indices = tf.range(len(vocab), dtype=tf.int64)\n",
    "table_init=tf.lookup.KeyValueTensorInitializer(vocab, indices)\n",
    "table = tf.lookup.StaticVocabularyTable(table_init, 2)\n",
    "\n",
    "examples=tf.constant(train['Sex'])\n",
    "examples_indices=table.lookup(examples)\n",
    "\n",
    "one_hot = tf.one_hot(examples_indices, depth=len(vocab)+2)\n",
    "\n",
    "vocab=train['Pclass'].drop_duplicates()\n",
    "indices = tf.range(len(vocab), dtype=tf.int64)\n",
    "table_init=tf.lookup.KeyValueTensorInitializer(vocab, indices)\n",
    "table = tf.lookup.StaticVocabularyTable(table_init, 2)\n",
    "\n",
    "examples=tf.constant(train['Pclass'])\n",
    "examples_indices=table.lookup(examples)\n",
    "\n",
    "one_hot2 = tf.one_hot(examples_indices, depth=len(vocab)+2)\n",
    "\n",
    "vocab=train['Embarked'].drop_duplicates().dropna()\n",
    "indices = tf.range(len(vocab), dtype=tf.int64)\n",
    "table_init=tf.lookup.KeyValueTensorInitializer(vocab, indices)\n",
    "table = tf.lookup.StaticVocabularyTable(table_init, 2)\n",
    "\n",
    "examples=tf.constant(train['Embarked'].fillna(\"None\"))\n",
    "examples_indices=table.lookup(examples)\n",
    "\n",
    "one_hot3 = tf.one_hot(examples_indices, depth=len(vocab)+2)\n",
    "\n",
    "\n",
    "x_train = tf.concat([one_hot,one_hot2,one_hot3],axis=1)\n",
    "y_train = np.ravel(train.Survived)\n",
    "\n",
    "keras.backend.clear_session()  \n",
    "np.random.seed(40)\n",
    "tf.random.set_seed(40)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(50, 10, input_length=x_train.shape[1]))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(16, activation='relu', input_shape=(10,)))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "            optimizer='adam',\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=50, batch_size=4, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5812e37fbc42ae0019c075dcd625ea6adf837b197758e07cfdfe5b415c77a600"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
