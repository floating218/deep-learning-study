{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Mean_Squared_error\n",
    "\n",
    " \n",
    "\n",
    "예측한 값과 실제 값 사이의 평균 제곱 오차를 정의한다. 공식이 매우 간단하며, 차가 커질수록 제곱 연산으로 인해서 값이 더욱 뚜렷해진다. 그리고 제곱으로 인해서 오차가 양수이든 음수이든 누적 값을 증가시킨다.\n",
    "\n",
    "\n",
    "RMSE(Root Mean Squared Error)\n",
    "\n",
    " \n",
    "\n",
    "MSE에 루트(√)를 씌운 것으로 MSE와 기본적으로 동일하다. MSE 값은 오류의 제곱을 구하기 때문에 실제 오류 평균보다 더 커지는 특성이 있어 MSE에 루트를 씌운 RMSE 은 값의 왜곡을 줄여준다.\n",
    "\n",
    " \n",
    "\n",
    "Binary Crossentropy\n",
    "\n",
    " \n",
    "\n",
    "실제 레이블과 예측 레이블 간의 교차 엔트로피 손실을 계산한다. 레이블 클래스(0, 1로 가정)가 2개만 존재할 때\n",
    "\n",
    "Binary Crossentropy를 사용하면 좋다. \n",
    "\n",
    " \n",
    "\n",
    "Categorical Crossentropy\n",
    "\n",
    "\n",
    "다중 분류 손실함수로 출력값이 one-hot encoding 된 결과로 나오고 실측 결과와의 비교시에도 실측 결과는 \n",
    "\n",
    "one-hot encoding 형태로 구성된다.\n",
    "\n",
    "예를 들면 출력 실측값이 아래와 같은 형태(one-hot encoding)로 만들어 줘야 하는 과정을 거쳐야 한다.\n",
    "[[0 0 1]\n",
    " [0 1 0]\n",
    " [1 0 0]]  (배치 사이즈 3개인 경우)\n",
    "\n",
    "네트웍 레이어 구성시 마지막에 Dense(3, activation='softmax') 로 3개의 클래스 각각 별로 positive 확률값이 나오게 된다.\n",
    "\n",
    "\n",
    "[0.2, 0.3, 0.5]\n",
    "\n",
    "\n",
    "위 네트웍 출력값과 실측값의 오차값을 계산한다.\n",
    "\n",
    " \n",
    "\n",
    " \n",
    "\n",
    "Sparse_Categorical_Crossentropy\n",
    "\n",
    " \n",
    "\n",
    "'categorical_entropy'처럼 다중 분류 손실함수이지만, 샘플 값은 정수형 자료이다. 예를 들어, 샘플 값이 아래와 같은 형태일 수 있다. (배치 사이즈 3개)\n",
    "\n",
    "\n",
    "[0, 1, 2] \n",
    "\n",
    "\n",
    "네트웍 구성은 동일하게 Dense(3, activation='softmax')로 하고 출력값도 3개가 나오게 된다.\n",
    "\n",
    "즉, 샘플 값을 입력하는 부분에서 별도 원핫 인코딩을 하지 않고 정수값 그대로 줄 수 있다. 이런 자료를 사용할 때, 컴파일 단계에서 손실 함수만  'sparse_categorical_crossentropy'로 바꿔주면 된다.\n",
    "\n",
    " \n",
    "\n",
    "그 외\n",
    "\n",
    " \n",
    "\n",
    "mean_absolute_error / mean_absolute_percentage_error \n",
    "\n",
    " \n",
    "\n",
    "mean_squared_logarithmic_error / cosine_proximity\n",
    "\n",
    " \n",
    "\n",
    "squared_hinge / hinge / categorical_hinge \n",
    "\n",
    " \n",
    "\n",
    "logcosh / kullback_leibler_divergence / poisson "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파이썬 ≥3.5 필수\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# 사이킷런 ≥0.20 필수\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "# 텐서플로 ≥2.0 필수\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "assert tf.__version__ >= \"2.0\"\n",
    "\n",
    "%load_ext tensorboard\n",
    "\n",
    "# 공통 모듈 임포트\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# 노트북 실행 결과를 동일하게 유지하기 위해\n",
    "np.random.seed(42)\n",
    "\n",
    "# 깔끔한 그래프 출력을 위해\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# 그림을 저장할 위치\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"deep\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"그림 저장:\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BinaryCrossentropy',\n",
       " 'CategoricalCrossentropy',\n",
       " 'CategoricalHinge',\n",
       " 'CosineSimilarity',\n",
       " 'Hinge',\n",
       " 'Huber',\n",
       " 'KLD',\n",
       " 'KLDivergence',\n",
       " 'LogCosh',\n",
       " 'Loss',\n",
       " 'MAE',\n",
       " 'MAPE',\n",
       " 'MSE',\n",
       " 'MSLE',\n",
       " 'MeanAbsoluteError',\n",
       " 'MeanAbsolutePercentageError',\n",
       " 'MeanSquaredError',\n",
       " 'MeanSquaredLogarithmicError',\n",
       " 'Poisson',\n",
       " 'Reduction',\n",
       " 'SparseCategoricalCrossentropy',\n",
       " 'SquaredHinge',\n",
       " 'binary_crossentropy',\n",
       " 'categorical_crossentropy',\n",
       " 'categorical_hinge',\n",
       " 'cosine_similarity',\n",
       " 'deserialize',\n",
       " 'get',\n",
       " 'hinge',\n",
       " 'kld',\n",
       " 'kullback_leibler_divergence',\n",
       " 'logcosh',\n",
       " 'mae',\n",
       " 'mape',\n",
       " 'mean_absolute_error',\n",
       " 'mean_absolute_percentage_error',\n",
       " 'mean_squared_error',\n",
       " 'mean_squared_logarithmic_error',\n",
       " 'mse',\n",
       " 'msle',\n",
       " 'poisson',\n",
       " 'serialize',\n",
       " 'sparse_categorical_crossentropy',\n",
       " 'squared_hinge']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[name for name in dir(keras.losses) if not name.startswith(\"_\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p36",
   "language": "python",
   "name": "conda_tensorflow2_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
